{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98e9a52b-f468-4cf3-abe8-256b4b46df3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42edebea-d418-4d45-ba09-a92b8fb07a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "440c4122-8a78-4284-9969-544fd9f7d701",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dsi/itaym/anaconda3/envs/maruloss/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ordinaloss.utils.pretrained_models\n",
      "loaded ordinaloss.utils.loss_utils\n",
      "loaded ordinaloss.utils.datasets\n"
     ]
    }
   ],
   "source": [
    "#from ordinaloss.utils.datasets import ImageFolder, create_transform_pipeline\n",
    "from ordinaloss.utils.pretrained_models import classification_model_densenet, classification_model_resnet, classification_model_vgg\n",
    "from ordinaloss.utils.utils import create_ordinal_cost_matrix\n",
    "\n",
    "\n",
    "from ordinaloss.engine.model_engine import OrdinalEngine\n",
    "from ordinaloss.utils.datasets import data_load\n",
    "\n",
    "from ordinaloss.utils.loss_utils import SinimLoss, SinimLossRevised, CSCELoss\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam, SGD\n",
    "import torch\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e846e2c-23fa-48c8-88fd-924869d48348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_transform = create_transform_pipeline(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.3) #These are hyperparameters. \n",
    "# test_transform = create_transform_pipeline() #Without color jitter for test pipeline\n",
    "\n",
    "# train_dataset = ImageFolder(\"../datasets/kneeKL224/train/\", transform=train_transform)\n",
    "# val_dataset = ImageFolder(\"../datasets/kneeKL224/val/\", transform = test_transform)\n",
    "# test_dataset = ImageFolder(\"../datasets/kneeKL224/test/\", transform = test_transform)\n",
    "# auto_test_dataset = ImageFolder(\"../datasets/kneeKL224/auto_test/\", transform = test_transform)\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size = 32, shuffle=True)\n",
    "# test_loader  = DataLoader(test_dataset,  batch_size = 128, shuffle=False)\n",
    "\n",
    "loaders, _, _ = data_load(\"../datasets/kneeKL224/\", 16)\n",
    "train_loader = loaders[\"train\"]\n",
    "test_loader = loaders[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b1bd860-b117-4e8a-9ee8-0e4bd026cadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = classification_model_vgg(\"vgg16\", num_classes = 5) #Could also be resnet34, resnet50, resnet101, resnet152, \n",
    "model = classification_model_vgg(\"vgg16\", num_classes = 5) #Could also be resnet34, resnet50, resnet101, resnet152, \n",
    "# model = classification_model_densenet(\"densenet121\", num_classes = 5) #Could also be densenet169, densenet201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "094be05d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20.,  1.,  2.,  3.,  4.],\n",
       "        [ 1., 20.,  1.,  2.,  3.],\n",
       "        [ 2.,  1., 20.,  1.,  2.],\n",
       "        [ 3.,  2.,  1., 20.,  1.],\n",
       "        [ 4.,  3.,  2.,  1., 20.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_ordinal_cost_matrix(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb73c1be-b7ea-4cf5-8045-55f0bd9f4872",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ordinaloss.utils.loss_utils import GirlsLoss, SinimLoss\n",
    "model = classification_model_vgg(\"vgg16\", num_classes = 5)\n",
    "\n",
    "def my_lambda_scheduler(epoch):\n",
    "    return (0.9 ** (epoch // 5))\n",
    "\n",
    "\n",
    "# engine = OrdinalEngine(model, \n",
    "#                        loss_fn = CSCELoss(create_ordinal_cost_matrix(5)), #CSCELoss model, matan, you know the dril.\n",
    "#                        device = device, #change to gpu, let me know if it doesnt work on GPU.\n",
    "#                        use_lr_scheduler=True, scheduler_lambda_fn = my_lambda_scheduler,\n",
    "#                        optimizer_fn=SGD, lr = 5.0e-4, weight_decay=5.0e-4)\n",
    "\n",
    "\n",
    "# engine = OrdinalEngine(model, \n",
    "#                        loss_fn = SinimLoss(), #CSCELoss model, matan, you know the dril.\n",
    "#                        device = device, #change to gpu, let me know if it doesnt work on GPU.\n",
    "#                        use_lr_scheduler=True, scheduler_lambda_fn = my_lambda_scheduler,\n",
    "#                        optimizer_fn=SGD, lr = 5.0e-4, weight_decay=5.0e-4)\n",
    "\n",
    "\n",
    "engine = OrdinalEngine(model, \n",
    "                       loss_fn = CSCELoss(create_ordinal_cost_matrix(5)), #CSCELoss model, matan, you know the dril.\n",
    "                       device = device, #change to gpu, let me know if it doesnt work on GPU.\n",
    "                       use_lr_scheduler=True, scheduler_lambda_fn = my_lambda_scheduler,\n",
    "                       optimizer_fn=Adam, lr = 1.0e-3, weight_decay=5.0e-2)                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25d5f8a2-5fc4-4ef1-969b-52de90659805",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training, epoch 0:   0%|          | 0/362 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 392.00 MiB (GPU 0; 10.76 GiB total capacity; 4.40 GiB already allocated; 336.44 MiB free; 5.26 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/dsi/itaym/projects/ordinaloss/training_model_exmaple.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bdsiaspl01/home/dsi/itaym/projects/ordinaloss/training_model_exmaple.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m engine\u001b[39m.\u001b[39;49mtrain(train_loader, test_loader, n_epochs \u001b[39m=\u001b[39;49m \u001b[39m20\u001b[39;49m)\n",
      "File \u001b[0;32m~/projects/ordinaloss/ordinaloss/engine/model_engine.py:203\u001b[0m, in \u001b[0;36mOrdinalEngine.train\u001b[0;34m(self, train_loader, test_loader, n_epochs)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(\u001b[39mself\u001b[39m, train_loader, test_loader\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, n_epochs\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m    202\u001b[0m     \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_epochs):\n\u001b[0;32m--> 203\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_epoch(train_loader)\n\u001b[1;32m    204\u001b[0m         \u001b[39mif\u001b[39;00m test_loader:\n\u001b[1;32m    205\u001b[0m             \u001b[39mprint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eval_epoch(test_loader))\n",
      "File \u001b[0;32m~/projects/ordinaloss/ordinaloss/engine/model_engine.py:114\u001b[0m, in \u001b[0;36mOrdinalEngine._train_epoch\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    111\u001b[0m cum_mae \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    113\u001b[0m \u001b[39mfor\u001b[39;00m X, y \u001b[39min\u001b[39;00m iterator: \n\u001b[0;32m--> 114\u001b[0m     stats \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_batch(X, y)\n\u001b[1;32m    115\u001b[0m     n \u001b[39m=\u001b[39m stats[\u001b[39m\"\u001b[39m\u001b[39mbatch_size\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    117\u001b[0m     cum_batch_size \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m n\n",
      "File \u001b[0;32m~/projects/ordinaloss/ordinaloss/engine/model_engine.py:102\u001b[0m, in \u001b[0;36mOrdinalEngine._train_batch\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     99\u001b[0m stats \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(X, y)\n\u001b[1;32m    101\u001b[0m stats[\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m--> 102\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m    103\u001b[0m \u001b[39mreturn\u001b[39;00m stats\n",
      "File \u001b[0;32m~/anaconda3/envs/maruloss/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:65\u001b[0m, in \u001b[0;36m_LRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m instance\u001b[39m.\u001b[39m_step_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     64\u001b[0m wrapped \u001b[39m=\u001b[39m func\u001b[39m.\u001b[39m\u001b[39m__get__\u001b[39m(instance, \u001b[39mcls\u001b[39m)\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/maruloss/lib/python3.9/site-packages/torch/optim/optimizer.py:113\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    112\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 113\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/maruloss/lib/python3.9/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/maruloss/lib/python3.9/site-packages/torch/optim/adam.py:157\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    153\u001b[0m                 max_exp_avg_sqs\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mmax_exp_avg_sq\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m    155\u001b[0m             state_steps\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m--> 157\u001b[0m     adam(params_with_grad,\n\u001b[1;32m    158\u001b[0m          grads,\n\u001b[1;32m    159\u001b[0m          exp_avgs,\n\u001b[1;32m    160\u001b[0m          exp_avg_sqs,\n\u001b[1;32m    161\u001b[0m          max_exp_avg_sqs,\n\u001b[1;32m    162\u001b[0m          state_steps,\n\u001b[1;32m    163\u001b[0m          amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    164\u001b[0m          beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    165\u001b[0m          beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    166\u001b[0m          lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    167\u001b[0m          weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    168\u001b[0m          eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    169\u001b[0m          maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    170\u001b[0m          foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    171\u001b[0m          capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m    173\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/anaconda3/envs/maruloss/lib/python3.9/site-packages/torch/optim/adam.py:213\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 213\u001b[0m func(params,\n\u001b[1;32m    214\u001b[0m      grads,\n\u001b[1;32m    215\u001b[0m      exp_avgs,\n\u001b[1;32m    216\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    217\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    218\u001b[0m      state_steps,\n\u001b[1;32m    219\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    220\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    221\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    222\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    223\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    224\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    225\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    226\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable)\n",
      "File \u001b[0;32m~/anaconda3/envs/maruloss/lib/python3.9/site-packages/torch/optim/adam.py:305\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[1;32m    303\u001b[0m     denom \u001b[39m=\u001b[39m (max_exp_avg_sqs[i]\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[1;32m    304\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 305\u001b[0m     denom \u001b[39m=\u001b[39m (exp_avg_sq\u001b[39m.\u001b[39;49msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[1;32m    307\u001b[0m param\u001b[39m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[39m=\u001b[39m\u001b[39m-\u001b[39mstep_size)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 0; 10.76 GiB total capacity; 4.40 GiB already allocated; 336.44 MiB free; 5.26 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "engine.train(train_loader, test_loader, n_epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d089ee8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('maruloss')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "7e97c30b3269f9da24b9fb2b586032ecca136d76e1141d9f46df271ff014add6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
